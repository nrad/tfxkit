functions:
  progressive_layer_tuning:
    function: "tfxkit.core.tuner.progressive_layer_tuning"
    parameters:
      units_choices: [64, 128, 256, 512]
      max_layers: 5
      patience: 1
    settings:
      max_trials: 20

  optimizer_tuning:
    function: "tfxkit.core.tuner.optimizer_tuning"
    parameters:
      optimizers: ["adam", "sgd", "rmsprop", "keras.optimizers.AdamW"]

  generic_tuning:
    function: "tfxkit.core.tuner.generic_tuner"
    parameters:
      model.parameters.layers_list: [ 1, 1028,  ]
      model.parameters.hidden_activation: ["relu", "tanh"]
      model.parameters.final_activation: ["sigmoid", "softmax"]
      optimizer.function: ["keras.optimizers.Adam", "keras.optimizers.AdamW"]

tuner:
  function: "keras_tuner.BayesianOptimization"
  parameters:
    objective: "val_loss"
    max_trials: 10
    executions_per_trial: 2
    alpha: 0.0001
    beta: 2.6
    directory: "tuner_dir"
    project_name: "HPTunning"
    overwrite: false
search:
  batch_size: 64000
  validation_split: 0.2

sequence: 
  # - optimizer_tuning
  - generic_tuning
